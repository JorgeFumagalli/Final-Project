# Final Project

\# ğŸ“ˆ PrevisÃ£o da InadimplÃªncia de CartÃµes de CrÃ©dito no Brasil



> Trabalho de ConclusÃ£o de Curso (TCC) do MBA em Data Science \& Analytics (USP/ESALQ): AnÃ¡lise comparativa de modelos de Machine Learning e Deep Learning para previsÃ£o de inadimplÃªncia, avaliando performance em diferentes regimes econÃ´micos.



---



\## ğŸ“Š \*\*VisÃ£o Geral\*\*



Este projeto foi desenvolvido como Trabalho de ConclusÃ£o de Curso (TCC) do MBA em Data Science \& Analytics da USP/ESALQ, analisando a previsÃ£o de inadimplÃªncia total de cartÃµes de crÃ©dito no Brasil utilizando variÃ¡veis macroeconÃ´micas mensais entre janeiro de 2015 e julho de 2025.



\### ğŸ¯ \*\*Objetivos do Projeto\*\*



\- Comparar performance de 5 modelos supervisionados: \*\*Linear Regression, SVR, XGBoost, MLP e LSTM\*\*

\- Avaliar impacto de choques estruturais (pandemia 2019-2021) no desempenho dos modelos

\- Identificar qual arquitetura Ã© mais adequada para diferentes regimes econÃ´micos

\- Fornecer subsÃ­dios prÃ¡ticos para seleÃ§Ã£o de tÃ©cnicas em gestÃ£o de risco de crÃ©dito



\### ğŸ† \*\*Principais ContribuiÃ§Ãµes\*\*



1\. \*\*AnÃ¡lise Dual de CenÃ¡rios\*\*: ComparaÃ§Ã£o entre sÃ©rie completa (FULL) vs perÃ­odo estÃ¡vel (EXCL)

2\. \*\*Descoberta MetodolÃ³gica\*\*: LSTM superior em alta volatilidade, SVR em estabilidade

3\. \*\*AplicaÃ§Ã£o PrÃ¡tica\*\*: OrientaÃ§Ã£o para seleÃ§Ã£o de modelos conforme contexto econÃ´mico

4\. \*\*Rigor AcadÃªmico\*\*: Metodologia completa com validaÃ§Ã£o temporal e mÃºltiplas mÃ©tricas



---



\## ğŸš€ \*\*Principais Resultados\*\*



\### âœ… \*\*CenÃ¡rio FULL (SÃ©rie Completa 2015-2025)\*\*



Inclui perÃ­odo de instabilidade fiscal 2019-2021.



| Modelo | MSE | RÂ² | MAPE (%) | DA (%) | Destaque |

|--------|-----|-----|----------|---------|----------|

| \*\*LSTM\*\* â­ | \*\*0.0179\*\* | \*\*0.7050\*\* | \*\*1.83\*\* | 40.00 | Melhor para alta volatilidade |

| Linear Regression | 0.0210 | 0.6542 | 2.05 | 44.00 | Baseline competitivo |

| XGBoost | 0.0228 | 0.6242 | 2.13 | 44.00 | Bom equilÃ­brio |

| SVR | 0.0572 | 0.0594 | 3.10 | 56.00 | Maior acerto direcional |

| MLP | 14.9447 | -244.79 | 56.59 | 48.00 | Overfitting severo |



> \*\*ğŸ’¡ Insight Chave:\*\* LSTM captura dependÃªncias temporais complexas em ambientes de alta volatilidade, explicando 70% da variÃ¢ncia da inadimplÃªncia.



\### âœ… \*\*CenÃ¡rio EXCL (Excluindo 2019-2021)\*\*



Remove perÃ­odo de instabilidade para analisar performance em ambiente estÃ¡vel.



| Modelo | MSE | RÂ² | MAPE (%) | DA (%) | Destaque |

|--------|-----|-----|----------|---------|----------|

| \*\*SVR\*\* â­ | \*\*0.0295\*\* | \*\*0.3559\*\* | \*\*2.26\*\* | 35.29 | Melhor para estabilidade |

| Linear Regression | 0.0370 | 0.1924 | 2.57 | 47.06 | Consistente |

| XGBoost | 0.1422 | -2.1029 | 5.40 | 41.18 | Perde generalizaÃ§Ã£o |

| LSTM | 0.2194 | -3.7858 | 7.50 | 47.06 | Requer mais dados |

| MLP | 0.9264 | -19.2102 | 12.36 | 41.18 | Inadequado |



> \*\*ğŸ’¡ Descoberta:\*\* SVR supera LSTM em ambiente estÃ¡vel, revelando que padrÃµes nÃ£o-lineares suaves sÃ£o melhor capturados por kernels RBF sem necessidade de memÃ³ria temporal complexa.



---



\## ğŸ’¡ \*\*Principais Descobertas\*\*



\### ğŸ¯ Descoberta 1: Contexto EconÃ´mico > Complexidade do Modelo



\*\*No cenÃ¡rio FULL (alta volatilidade):\*\*

\- \*\*LSTM:\*\* RÂ² = 0.70, MAPE = 1.83%

\- Capacidade de capturar dependÃªncias temporais durante choques macroeconÃ´micos

\- Volatilidade extrema da pandemia exige memÃ³ria de longo prazo



\*\*No cenÃ¡rio EXCL (estabilidade):\*\*

\- \*\*SVR:\*\* RÂ² = 0.36, MAPE = 2.26%

\- PadrÃµes nÃ£o-lineares mais suaves favorecem kernel RBF

\- Modelos mais simples suficientes sem choques estruturais



\*\*ImplicaÃ§Ã£o PrÃ¡tica:\*\* A escolha do modelo deve considerar o regime econÃ´mico vigente, nÃ£o apenas mÃ©tricas de treino.



\### ğŸ¯ Descoberta 2: Trade-off entre Complexidade e Volume de Dados



\- \*\*MLP:\*\* Performance ruim em ambos cenÃ¡rios

\- SÃ©ries temporais curtas (126 meses) insuficientes para deep learning complexo

\- LSTM funciona por ter arquitetura especializada em sequÃªncias

\- \*\*LiÃ§Ã£o:\*\* Deep learning requer > 200-300 observaÃ§Ãµes para generalizar bem



\### ğŸ¯ Descoberta 3: Baseline Linear Surpreendentemente Competitivo



\- \*\*Linear Regression:\*\* RÂ² = 0.65 (FULL), 0.19 (EXCL)

\- 65% da inadimplÃªncia explicada por relaÃ§Ãµes aproximadamente lineares

\- Modelos simples podem ser suficientes para interpretabilidade

\- \*\*LiÃ§Ã£o:\*\* Sempre compare com baseline antes de usar modelos complexos



\### ğŸ¯ Descoberta 4: Acerto Direcional â‰  Magnitude do Erro



\- \*\*SVR:\*\* Maior DA (56%) no FULL, mas maior MAPE

\- PrevÃª corretamente direÃ§Ã£o do movimento (alta/baixa)

\- Mas erra na magnitude exata

\- \*\*AplicaÃ§Ã£o:\*\* Ideal para decisÃµes estratÃ©gicas (tendÃªncia futura)



\### ğŸ¯ Descoberta 5: PerÃ­odos de Crise ContÃªm InformaÃ§Ã£o Valiosa



\- ExclusÃ£o 2019-2021 resulta em piora geral de performance

\- Choques estruturais revelam relaÃ§Ãµes funcionais importantes

\- Modelos treinados com crises sÃ£o mais robustos

\- \*\*LiÃ§Ã£o:\*\* NÃ£o exclua outliers antes de avaliar seu valor informacional



---



\## ğŸ“Š \*\*Dados e VariÃ¡veis\*\*



\### Fonte dos Dados



\- \*\*Banco Central do Brasil\*\* - Sistema Gerenciador de SÃ©ries Temporais (SGS)

\- \*\*IBGE\*\* - Ãndice Nacional de PreÃ§os ao Consumidor Amplo (IPCA)

\- \*\*PerÃ­odo:\*\* Janeiro/2015 a Julho/2025 (126 observaÃ§Ãµes mensais)



\### VariÃ¡veis Preditoras



| VariÃ¡vel | DescriÃ§Ã£o | Fonte |

|----------|-----------|-------|

| \*\*Taxa Selic\*\* | Taxa bÃ¡sica de juros da economia brasileira | BCB |

| \*\*IBC-Br Dessazonalizado\*\* | Ãndice de Atividade EconÃ´mica (proxy do PIB) | BCB |

| \*\*IPCA\*\* | InflaÃ§Ã£o mensal oficial | IBGE |

| \*\*Comprometimento de Renda\*\* | % da renda comprometida com dÃ­vidas | BCB |

| \*\*Endividamento das FamÃ­lias\*\* | NÃ­vel total de endividamento em relaÃ§Ã£o Ã  renda | BCB |



\### VariÃ¡vel Target



\- \*\*InadimplÃªncia Total de CartÃ£o de CrÃ©dito\*\* (% do saldo total inadimplente)

\- Fonte: Banco Central do Brasil

\- SÃ©rie oficial mensal



\### Feature Engineering



\*\*Features Criadas:\*\*

```python

\# Temporal

\- lag\_1\_target: Valor anterior da inadimplÃªncia

&nbsp; (Ãºnica feature derivada mantida apÃ³s anÃ¡lise de colinearidade)



\# VariÃ¡veis originais

\- IBC-Br dessazonalizado (melhor performance vs versÃ£o original)

\- RemoÃ§Ã£o de lags de variÃ¡veis independentes (evitar multicolinearidade)

```



\*\*DecisÃµes de Engenharia:\*\*

\- Testados mÃºltiplos lags â†’ aumentaram colinearidade e pioraram RÂ²

\- Testado IBC-Br original vs dessazonalizado vs ambos â†’ dessazonalizado venceu

\- Lag 1 da target altamente informativo (consistente com literatura de persistÃªncia)



---



\## ğŸ”¬ \*\*Metodologia\*\*



\### CenÃ¡rios de AnÃ¡lise



\*\*CENÃRIO FULL (Completo)\*\*

\- \*\*PerÃ­odo:\*\* Jan/2015 a Jul/2025

\- \*\*N:\*\* 126 observaÃ§Ãµes

\- \*\*CaracterÃ­sticas:\*\* Inclui instabilidade fiscal 2019-2021

\- \*\*Objetivo:\*\* Avaliar capacidade de lidar com volatilidade extrema



\*\*CENÃRIO EXCL (ExclusÃ£o)\*\*

\- \*\*PerÃ­odo:\*\* Jan/2015 a Dez/2018 + Jan/2022 a Jul/2025

\- \*\*N:\*\* 90 observaÃ§Ãµes

\- \*\*CaracterÃ­sticas:\*\* Remove choques da pandemia

\- \*\*Objetivo:\*\* Avaliar performance em ambiente estÃ¡vel



\*\*Justificativa da ExclusÃ£o 2019-2021:\*\*

\- Medidas fiscais extraordinÃ¡rias durante pandemia

\- PostergaÃ§Ã£o de despesas obrigatÃ³rias

\- DeterioraÃ§Ã£o acentuada de indicadores fiscais

\- Ruptura estrutural documentada (TCU, 2021; FGV IBRE, 2022)



\### PrÃ©-processamento



```python

\# PadronizaÃ§Ã£o

\- StandardScaler (mÃ©dia 0, desvio padrÃ£o 1)

\- NecessÃ¡rio para SVR, MLP e LSTM



\# DivisÃ£o Temporal

\- Train: 80% das observaÃ§Ãµes

\- Test: 20% das observaÃ§Ãµes

\- Respeita ordem cronolÃ³gica (evita data leakage)



\# Dados

\- Nenhum valor faltante identificado

\- SÃ©ries completas no perÃ­odo analisado

```



\### Modelos Implementados



\#### 1. \*\*Linear Regression (Baseline)\*\*



```python

from sklearn.linear\_model import LinearRegression



\# Modelo paramÃ©trico simples (OLS)

model = LinearRegression()

```



\*\*Por que usar:\*\*

\- Estabelece baseline para comparaÃ§Ã£o

\- Avalia presenÃ§a de padrÃµes lineares

\- MÃ¡xima interpretabilidade



\#### 2. \*\*Support Vector Regression (SVR)\*\*



```python

from sklearn.svm import SVR



model = SVR(

&nbsp;   kernel='rbf',

&nbsp;   C=100,

&nbsp;   gamma='scale',

&nbsp;   epsilon=0.1

)

```



\*\*CaracterÃ­sticas:\*\*

\- Captura relaÃ§Ãµes nÃ£o-lineares via kernel RBF

\- Eficiente em datasets pequenos-mÃ©dios

\- Robusto a outliers



\#### 3. \*\*XGBoost\*\*



```python

import xgboost as xgb



model = xgb.XGBRegressor(

&nbsp;   n\_estimators=1000,

&nbsp;   max\_depth=7,

&nbsp;   learning\_rate=0.01,

&nbsp;   subsample=0.8,

&nbsp;   colsample\_bytree=0.8,

&nbsp;   objective='reg:squarederror',

&nbsp;   early\_stopping\_rounds=50

)

```



\*\*CaracterÃ­sticas:\*\*

\- State-of-the-art para dados tabulares

\- RegularizaÃ§Ã£o built-in (menos overfitting)

\- Feature importance nativa



\#### 4. \*\*Multilayer Perceptron (MLP)\*\*



```python

from tensorflow.keras.models import Sequential

from tensorflow.keras.layers import Dense, Dropout



model = Sequential(\[

&nbsp;   Dense(64, activation='relu'),

&nbsp;   Dropout(0.2),

&nbsp;   Dense(32, activation='relu'),

&nbsp;   Dropout(0.2),

&nbsp;   Dense(16, activation='relu'),

&nbsp;   Dense(1)

])

```



\*\*CaracterÃ­sticas:\*\*

\- Rede neural feedforward

\- Captura relaÃ§Ãµes nÃ£o-lineares complexas

\- Requer mais dados para treinar bem



\#### 5. \*\*Long Short-Term Memory (LSTM)\*\*



```python

from tensorflow.keras.layers import LSTM



model = Sequential(\[

&nbsp;   LSTM(128, return\_sequences=True, input\_shape=(lookback, n\_features)),

&nbsp;   Dropout(0.2),

&nbsp;   LSTM(64, return\_sequences=False),

&nbsp;   Dropout(0.2),

&nbsp;   Dense(32, activation='relu'),

&nbsp;   Dense(1)

])



\# OtimizaÃ§Ã£o

model.compile(

&nbsp;   optimizer='adam',

&nbsp;   loss='mse',

&nbsp;   metrics=\['mae']

)



\# Early Stopping

early\_stop = EarlyStopping(patience=20, restore\_best\_weights=True)

```



\*\*CaracterÃ­sticas:\*\*

\- Especializada em sÃ©ries temporais

\- Captura dependÃªncias de longo prazo

\- MemÃ³ria de curto e longo prazo



\*\*TÃ©cnicas Aplicadas:\*\*

\- Early Stopping (patience=20)

\- Dropout para regularizaÃ§Ã£o

\- Validation split interno



\### MÃ©tricas de AvaliaÃ§Ã£o



\*\*MSE (Mean Squared Error):\*\*

```

MSE = (1/n) Ã— Î£(y\_i - Å·\_i)Â²

```

\- Penaliza erros grandes

\- SensÃ­vel a outliers



\*\*RÂ² (Coeficiente de DeterminaÃ§Ã£o):\*\*

```

RÂ² = 1 - Î£(y\_i - Å·\_i)Â² / Î£(y\_i - È³)Â²

```

\- ProporÃ§Ã£o da variÃ¢ncia explicada

\- Valores < 0 indicam performance pior que mÃ©dia



\*\*MAPE (Mean Absolute Percentage Error):\*\*

```

MAPE = (100/n) Ã— Î£|((y\_i - Å·\_i) / y\_i)|

```

\- Erro percentual mÃ©dio

\- InterpretÃ¡vel em termos relativos



\*\*DA (Directional Accuracy):\*\*

```

DA = (1/(n-1)) Ã— Î£ ğŸ™\[(y\_i - y\_{i-1})(Å·\_i - Å·\_{i-1}) > 0]

```

\- Acerto da direÃ§Ã£o do movimento

\- Crucial para decisÃµes estratÃ©gicas



---



\## ğŸ“ˆ \*\*AnÃ¡lise Comparativa Detalhada\*\*



\### Desempenho por CenÃ¡rio



\#### \*\*CENÃRIO FULL: Alta Volatilidade Favorece LSTM\*\*



\*\*Ranking de Performance:\*\*

1\. ğŸ¥‡ \*\*LSTM\*\*: MSE=0.0179, RÂ²=0.70, MAPE=1.83%

2\. ğŸ¥ˆ \*\*Linear\*\*: MSE=0.0210, RÂ²=0.65, MAPE=2.05%

3\. ğŸ¥‰ \*\*XGBoost\*\*: MSE=0.0228, RÂ²=0.62, MAPE=2.13%

4\. \*\*SVR\*\*: MSE=0.0572, RÂ²=0.06, MAPE=3.10%

5\. \*\*MLP\*\*: MSE=14.94, RÂ²=-244.79, MAPE=56.59%



\*\*AnÃ¡lise:\*\*

\- LSTM explica 70% da variÃ¢ncia

\- Erro percentual de apenas 1.83%

\- Superior em capturar choques da pandemia

\- Linear Regression surpreendentemente competitiva (RÂ²=0.65)



\#### \*\*CENÃRIO EXCL: Estabilidade Favorece SVR\*\*



\*\*Ranking de Performance:\*\*

1\. ğŸ¥‡ \*\*SVR\*\*: MSE=0.0295, RÂ²=0.36, MAPE=2.26%

2\. ğŸ¥ˆ \*\*Linear\*\*: MSE=0.0370, RÂ²=0.19, MAPE=2.57%

3\. ğŸ¥‰ \*\*XGBoost\*\*: MSE=0.1422, RÂ²=-2.10, MAPE=5.40%

4\. \*\*LSTM\*\*: MSE=0.2194, RÂ²=-3.79, MAPE=7.50%

5\. \*\*MLP\*\*: MSE=0.9264, RÂ²=-19.21, MAPE=12.36%



\*\*AnÃ¡lise:\*\*

\- SVR Ãºnico com RÂ² positivo

\- LSTM perde performance sem volatilidade

\- XGBoost sofre com reduÃ§Ã£o de amostra

\- PadrÃµes nÃ£o-lineares suaves favorecem kernel RBF



\### ComparaÃ§Ã£o Visual



\*\*MudanÃ§a de Performance (FULL â†’ EXCL):\*\*



| Modelo | Î” MSE | Î” RÂ² | Î” MAPE | InterpretaÃ§Ã£o |

|--------|-------|------|--------|---------------|

| LSTM | +1125% | -530% | +310% | Grande degradaÃ§Ã£o |

| XGBoost | +523% | -430% | +154% | SensÃ­vel a amostra |

| Linear | +76% | -71% | +25% | Mais robusto |

| SVR | -48% | +500% | -27% | \*\*Melhora!\*\* |

| MLP | -94% | +92% | -78% | Melhora relativa |



\*\*ConclusÃ£o:\*\* SVR Ã© o Ãºnico modelo que \*\*melhora\*\* com a remoÃ§Ã£o dos choques, enquanto modelos complexos degradam significativamente.



---



\## ğŸ¯ \*\*RecomendaÃ§Ãµes PrÃ¡ticas\*\*



\### Quando Usar Cada Modelo



\#### \*\*LSTM (Long Short-Term Memory)\*\*



\*\*âœ… Use quando:\*\*

\- SÃ©ries com alta volatilidade e choques estruturais

\- Disponibilidade de dados histÃ³ricos longos (>200 observaÃ§Ãµes idealmente)

\- Recursos computacionais suficientes (GPU recomendada)

\- Necessidade de capturar dependÃªncias de longo prazo

\- Contexto: crises econÃ´micas, mudanÃ§as estruturais



\*\*âŒ Evite quando:\*\*

\- SÃ©ries curtas (<100 observaÃ§Ãµes)

\- Ambiente econÃ´mico estÃ¡vel

\- Necessidade de mÃ¡xima interpretabilidade

\- RestriÃ§Ãµes computacionais



\*\*Exemplo:\*\* PrevisÃ£o durante crises (COVID-19, crise 2008)



---



\#### \*\*SVR (Support Vector Regression)\*\*



\*\*âœ… Use quando:\*\*

\- Ambiente econÃ´mico estÃ¡vel

\- PadrÃµes nÃ£o-lineares suaves

\- Datasets pequenos-mÃ©dios (50-500 observaÃ§Ãµes)

\- Necessidade de robustez a outliers

\- Recursos computacionais limitados



\*\*âŒ Evite quando:\*\*

\- SÃ©ries muito longas (>1000 obs) - custo computacional alto

\- PadrÃµes predominantemente lineares

\- Necessidade de interpretabilidade total



\*\*Exemplo:\*\* PrevisÃ£o de curto prazo em perÃ­odos normais



---



\#### \*\*XGBoost\*\*



\*\*âœ… Use quando:\*\*

\- Bom equilÃ­brio entre complexidade e performance

\- Necessidade de interpretabilidade (feature importance)

\- ProduÃ§Ã£o com baixa latÃªncia

\- InteraÃ§Ãµes nÃ£o-lineares entre variÃ¡veis

\- Prioridade para robustez



\*\*âŒ Evite quando:\*\*

\- PadrÃµes lineares sÃ£o suficientes

\- SÃ©ries muito curtas (<50 observaÃ§Ãµes)

\- DependÃªncias temporais de longo prazo sÃ£o cruciais



\*\*Exemplo:\*\* Sistemas de decisÃ£o em tempo real



---



\#### \*\*Linear Regression\*\*



\*\*âœ… Use quando:\*\*

\- Baseline rÃ¡pido necessÃ¡rio

\- RelaÃ§Ãµes predominantemente lineares

\- MÃ¡xima interpretabilidade necessÃ¡ria

\- Recursos computacionais muito limitados

\- Compliance e auditoria (explicabilidade total)



\*\*âŒ Evite quando:\*\*

\- PadrÃµes claramente nÃ£o-lineares

\- InteraÃ§Ãµes complexas entre variÃ¡veis

\- Performance Ã© prioridade absoluta



\*\*Exemplo:\*\* RelatÃ³rios regulatÃ³rios, explicaÃ§Ãµes para executivos



---



\### AplicaÃ§Ã£o em GestÃ£o de Risco de CrÃ©dito



\#### \*\*CenÃ¡rio 1: PerÃ­odos Normais (Estabilidade)\*\*

```

Modelo recomendado: SVR ou Linear Regression

Justificativa: Estabilidade + interpretabilidade

FrequÃªncia de retreino: Trimestral

Threshold de alerta: MAPE > 3%

```



\#### \*\*CenÃ¡rio 2: PerÃ­odos de Crise (Alta Volatilidade)\*\*

```

Modelo recomendado: LSTM

Justificativa: Captura choques e dependÃªncias complexas

FrequÃªncia de retreino: Mensal

Threshold de alerta: MAPE > 2.5%

```



\#### \*\*CenÃ¡rio 3: ProduÃ§Ã£o (Real-time)\*\*

```

Modelo recomendado: XGBoost

Justificativa: EquilÃ­brio performance/latÃªncia

FrequÃªncia de retreino: Bimestral

Threshold de alerta: RÂ² < 0.5

```



\#### \*\*CenÃ¡rio 4: RelatÃ³rios RegulatÃ³rios\*\*

```

Modelo recomendado: Linear Regression

Justificativa: MÃ¡xima transparÃªncia

FrequÃªncia: Anual

DocumentaÃ§Ã£o: Completa com coeficientes interpretÃ¡veis

```



---



\## ğŸ› ï¸ \*\*Tecnologias Utilizadas\*\*



\### Core Libraries

```python

pandas>=1.5.0          # ManipulaÃ§Ã£o de dados

numpy>=1.23.0          # ComputaÃ§Ã£o numÃ©rica

scikit-learn>=1.0.0    # Machine Learning tradicional

xgboost>=1.7.0         # Gradient Boosting

tensorflow>=2.10.0     # Deep Learning

keras>=2.10.0          # Interface DL

```



\### Analysis \& Visualization

```python

matplotlib>=3.6.0      # VisualizaÃ§Ãµes

seaborn>=0.12.0        # GrÃ¡ficos estatÃ­sticos

statsmodels>=0.13.0    # AnÃ¡lise de sÃ©ries temporais

```



---



\## ğŸ“ \*\*Estrutura do Projeto\*\*



```

inadimplencia-cartoes-ml/

â”‚

â”œâ”€â”€ data/

â”‚   â”œâ”€â”€ raw/                    # Dados do BCB e IBGE

â”‚   â””â”€â”€ processed/              # Dados processados

â”‚

â”œâ”€â”€ notebooks/

â”‚   â”œâ”€â”€ 01\_coleta\_dados.ipynb

â”‚   â”œâ”€â”€ 02\_eda\_series\_temporais.ipynb

â”‚   â”œâ”€â”€ 03\_feature\_engineering.ipynb

â”‚   â”œâ”€â”€ 04\_baseline\_models.ipynb

â”‚   â”œâ”€â”€ 05\_ml\_models.ipynb

â”‚   â”œâ”€â”€ 06\_deep\_learning.ipynb

â”‚   â””â”€â”€ 07\_comparacao\_final.ipynb

â”‚

â”œâ”€â”€ src/

â”‚   â”œâ”€â”€ data\_preprocessing.py

â”‚   â”œâ”€â”€ feature\_engineering.py

â”‚   â”œâ”€â”€ models.py

â”‚   â””â”€â”€ evaluation.py

â”‚

â”œâ”€â”€ models/

â”‚   â”œâ”€â”€ lstm\_full.h5

â”‚   â”œâ”€â”€ svr\_excl.pkl

â”‚   â””â”€â”€ model\_comparison.csv

â”‚

â”œâ”€â”€ reports/

â”‚   â”œâ”€â”€ TCC\_Final.pdf

â”‚   â””â”€â”€ figures/

â”‚

â””â”€â”€ README.md

```



---



\## ğŸ¯ \*\*Como Usar\*\*



\### 1. InstalaÃ§Ã£o



```bash

git clone https://github.com/JorgeFumagalli/Final-Project.git

cd Final-Project



python -m venv venv

source venv/bin/activate



pip install -r requirements.txt

```



\### 2. Coleta de Dados



```python

\# Os dados podem ser obtidos do SGS do Banco Central

\# Links disponÃ­veis no notebook 01\_coleta\_dados.ipynb



\# Ou use dados jÃ¡ processados em data/processed/

```



\### 3. Reproduzir AnÃ¡lises



```bash

\# Execute notebooks na ordem

jupyter notebook notebooks/



\# Ou rode pipeline completo

python src/run\_pipeline.py --scenario full

python src/run\_pipeline.py --scenario excl

```



\### 4. Fazer PrevisÃµes



```python

from tensorflow.keras.models import load\_model

import joblib



\# Carregue modelo apropriado

lstm\_model = load\_model('models/lstm\_full.h5')  # Para alta volatilidade

svr\_model = joblib.load('models/svr\_excl.pkl')  # Para estabilidade



\# Prepare dados (mesmo preprocessing do treino)

import pandas as pd

new\_data = pd.DataFrame({

&nbsp;   'Selic': \[10.5],

&nbsp;   'IBC-Br': \[135.2],

&nbsp;   'IPCA': \[0.45],

&nbsp;   'Comprometimento': \[28.5],

&nbsp;   'Endividamento': \[50.2],

&nbsp;   'lag\_1\_target': \[5.2]  # InadimplÃªncia do mÃªs anterior

})



\# Padronize

from sklearn.preprocessing import StandardScaler

scaler = joblib.load('models/scaler.pkl')

X\_scaled = scaler.transform(new\_data)



\# PrevisÃ£o

pred\_lstm = lstm\_model.predict(X\_scaled.reshape(1, 1, -1))

pred\_svr = svr\_model.predict(X\_scaled)



print(f"PrevisÃ£o LSTM: {pred\_lstm\[0]\[0]:.2f}%")

print(f"PrevisÃ£o SVR: {pred\_svr\[0]:.2f}%")

```



---



\## ğŸ”® \*\*Trabalhos Futuros\*\*



\### Melhorias Planejadas

\- \[ ] Incorporar variÃ¡veis microeconÃ´micas (renda per capita, desemprego por regiÃ£o)

\- \[ ] Testar modelos hÃ­bridos (ensemble ML + DL)

\- \[ ] Implementar detecÃ§Ã£o automÃ¡tica de quebras estruturais

\- \[ ] Sistema de seleÃ§Ã£o automÃ¡tica de modelo baseado em volatilidade

\- \[ ] PrevisÃ£o probabilÃ­stica (intervalos de confianÃ§a)



\### ExtensÃµes AcadÃªmicas

\- \[ ] AnÃ¡lise de outras modalidades de crÃ©dito (consignado, veÃ­culos)

\- \[ ] ComparaÃ§Ã£o internacional (Brasil vs outros emergentes)

\- \[ ] AnÃ¡lise de causalidade (Granger, VAR)

\- \[ ] Incorporar variÃ¡veis de polÃ­tica monetÃ¡ria



---



\## ğŸ“š \*\*ReferÃªncias\*\*



\### Principais ReferÃªncias do TCC



\*\*Metodologia:\*\*

\- Hochreiter \& Schmidhuber (1997) - Long Short-Term Memory

\- Chen \& Guestrin (2016) - XGBoost: A Scalable Tree Boosting System

\- Cortes \& Vapnik (1995) - Support-vector networks

\- Hyndman \& Athanasopoulos (2018) - Forecasting: Principles and Practice



\*\*AplicaÃ§Ãµes em FinanÃ§as:\*\*

\- Barboza et al. (2017) - Machine learning models and bankruptcy prediction

\- Alonso \& CarbÃ³ (2020) - Machine learning in credit risk

\- Wang \& Zhang (2024) - Credit risk prediction using deep learning



\*\*Contexto Brasileiro:\*\*

\- SicsÃº et al. (2022) - CrÃ©dito, crescimento e estabilidade financeira no Brasil

\- Banco Central do Brasil (2025) - Sistema Gerenciador de SÃ©ries Temporais

\- TCU (2021) - RelatÃ³rio das Contas do Governo da RepÃºblica



\*\*Veja referÃªncias completas no TCC (reports/TCC\_Final.pdf)\*\*



---



\## ğŸ‘¤ \*\*Autor\*\*



\*\*Jorge Luiz Fumagalli\*\*



\*\*FormaÃ§Ã£o:\*\*

\- ğŸ“ MBA em Data Science \& Analytics - USP/ESALQ (2024-2026)

\- ğŸ“ Engenharia de ProduÃ§Ã£o - UFTM

\- ğŸ“ TÃ©cnico em InformÃ¡tica - ETEC



\*\*Orientador do TCC:\*\*

\- Prof. Me. Diego Pedroso dos Santos



\*\*Contato:\*\*

\- ğŸ’¼ LinkedIn: \[linkedin.com/in/jorge-fumagalli-bb8975121](https://www.linkedin.com/in/jorge-fumagalli-bb8975121/)

\- ğŸ“§ Email: jorgefumagalli@yahoo.com.br

\- ğŸ™ GitHub: \[github.com/JorgeFumagalli](https://github.com/JorgeFumagalli)



---



\## ğŸ“„ \*\*LicenÃ§a\*\*



Este projeto estÃ¡ sob a licenÃ§a MIT.



---



\## ğŸ™ \*\*Agradecimentos\*\*



\- Prof. Diego Pedroso dos Santos pela orientaÃ§Ã£o

\- USP/ESALQ pelo programa de MBA em Data Science \& Analytics

\- Banco Central do Brasil pela disponibilizaÃ§Ã£o dos dados

\- Comunidades open-source de Machine Learning e Deep Learning



---



\## ğŸ“– \*\*CitaÃ§Ã£o\*\*



Se este trabalho foi Ãºtil para sua pesquisa, considere citar:



```bibtex

@mastersthesis{fumagalli2026,

&nbsp; author  = {Fumagalli, Jorge Luiz},

&nbsp; title   = {PrevisÃ£o da InadimplÃªncia de CartÃµes de CrÃ©dito no Brasil com Modelos de Aprendizado de MÃ¡quina},

&nbsp; school  = {USP/ESALQ - MBA em Data Science \& Analytics},

&nbsp; year    = {2026},

&nbsp; type    = {Trabalho de ConclusÃ£o de Curso}

}

```



---



\## â­ \*\*Se este projeto foi Ãºtil, considere dar uma estrela!\*\*



---



\*\*ğŸ’¡ DÃºvidas? SugestÃµes? Feedbacks sÃ£o sempre bem-vindos!\*\*



\[Abrir Issue](https://github.com/JorgeFumagalli/Final-Project/issues) | \[Pull Requests](https://github.com/JorgeFumagalli/Final-Project/pulls)

